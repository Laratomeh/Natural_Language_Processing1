{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "miniProject3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('senseval')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4waDiRUBCue0",
        "outputId": "3be276ab-13e2-45ce-ace6-7fbfd0de38f2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]   Package senseval is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "from nltk.classify import accuracy\n",
        "from nltk.corpus import senseval, wordnet, stopwords\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "DUb_91wjCx9l"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pos_tag(tag):\n",
        "\tif len(tag) == 0:\n",
        "\t\treturn tag\n",
        "\tif tag[0] == \"J\":\n",
        "\t\treturn wordnet.ADJ\n",
        "\telif tag[0] == 'V':\n",
        "\t\treturn wordnet.VERB\n",
        "\telif tag[0] == 'N':\n",
        "\t\treturn wordnet.NOUN\n",
        "\telif tag[0] == 'R':\n",
        "\t\treturn wordnet.ADV\n",
        "\telse:\t\n",
        "\t\treturn wordnet.NOUN"
      ],
      "metadata": {
        "id": "MeWkZJiSNRcM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(instance, window_size):\n",
        "\tposition = instance.position\n",
        "\tcontext = instance.context\n",
        "\tsense = instance.senses[0]\n",
        "\tassert len(instance.senses) == 1, \"{}\".format(instance.senses)\n",
        "\tfeatures = {}\n",
        "\tfeatures[\"initial_position_idx\"] = position\n",
        "\tfeatures[\"len_context\"] = len(context)\n",
        "\tnew_context, new_position = [], position\n",
        "\tfor i in range(len(context)):\n",
        "\t\tif not isinstance(context[i], (tuple, list)):\n",
        "\t\t\tif i < position:\n",
        "\t\t\t\tnew_position -= 1\n",
        "\t\telif context[i][0].lower() in string.punctuation or context[i][0].lower() in stopwords.words(\"english\") or context[i][0] == \"``\" or context[i][0] == \"''\" or len(context[i][0]) == 0:\n",
        "\t\t\tif i < position:\n",
        "\t\t\t\tnew_position -= 1\n",
        "\t\telse:\n",
        "\t\t\tnew_context.append(context[i])\n",
        "\tnew_context = [(0, \"None1\")] * (window_size // 2) + new_context + [(0, \"None2\")] * (window_size // 2)\n",
        "\tnew_position += window_size // 2\n",
        "\tfeatures[\"new_position_idx\"] = new_position\n",
        "\tfeatures[\"len_context_after_removal\"] = len(new_context)\n",
        "\tfor i in range(new_position - window_size // 2, new_position + window_size // 2 + 1):\n",
        "\t\ttag = new_context[i][1]\n",
        "\t\treduced_tag = get_pos_tag(tag)\n",
        "\t\tfeatures[\"part_of_speech_{}\".format(i - new_position)] = tag\n",
        "\t\tfeatures[\"reduced_part_of_speech_{}\".format(i - new_position)] = reduced_tag\n",
        "\t\tfeatures[\"{}\".format(tag)] = features.get(\"{}\".format(tag), 0) + 1 \n",
        "\t\tfeatures[\"{}\".format(reduced_tag)] = features.get(\"{}\".format(reduced_tag), 0) + 1 \n",
        "\treturn (features, sense)"
      ],
      "metadata": {
        "id": "jj84nTUDNSqV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in [\"line\", \"hard\", \"serve\", \"interest\"]:\n",
        "\tinst = senseval.instances(\"{}.pos\".format(word))\n",
        "\tSIZE_SPLIT = 0.75\n",
        "\tdata = [get_features(inst[i], window_size=12) for i in range(len(inst))]\n",
        "\ttrain, validation = data[:int(SIZE_SPLIT * len(data))], data[int(SIZE_SPLIT * len(data)):]\n",
        "\tmodel = nltk.NaiveBayesClassifier.train(train)\n",
        "\twith open(\"./NaiveBayes_{}\".format(word), \"w+\") as f:\n",
        "\t\tf.write(\"Word: {}\\n\".format(word))\n",
        "\t\tf.write(\"Data length: {}\\n\".format(len(data)))\n",
        "\t\tf.write(\"Word senses: {}\\n\".format(set([sense for (_, sense) in data])))\n",
        "\t\tf.write(\"Accuracy on train: {}\\n\".format(accuracy(model, train)))\n",
        "\t\tf.write(\"Accuracy on validation: {}\\n\".format(accuracy(model, validation)))\n",
        "\t\ttable = PrettyTable()\n",
        "\t\ttable.field_names = [\"Predicted\", \"Truth\"]\n",
        "\t\tfor i in range(min(150, len(validation))):\n",
        "\t\t\tpredicted_label = model.classify(validation[i][0])\n",
        "\t\t\tactual_label = validation[i][1]\n",
        "\t\t\ttable.add_row([predicted_label, actual_label])\n",
        "\t\tf.write(str(table))"
      ],
      "metadata": {
        "id": "5Ff9uAGKyrmV"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}