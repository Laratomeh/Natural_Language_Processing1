{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_Lab2_Tomeh_Lara.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The Stanford POS Tagger\n"
      ],
      "metadata": {
        "id": "TOiBlh5oa6ze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Web app version: http://nlp.stanford.edu:8080/parser/\n",
        "\n",
        "Newer version of the NLTK interface, requires running a java server locally: https://github.com/nltk/nltk/wiki/Stanford-CoreNLP-API-in-NLTK\n"
      ],
      "metadata": {
        "id": "cfHeXLEUgIKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading the tagger and models"
      ],
      "metadata": {
        "id": "MOXWLw-SbCpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and uzip the model. You can do the same thing on your own computer to be able to use it locally."
      ],
      "metadata": {
        "id": "rmImjTN1bZMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!wget 'https://nlp.stanford.edu/software/stanford-tagger-4.2.0.zip'\n",
        "!unzip './stanford-tagger-4.2.0.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nYqHkCnbF0o",
        "outputId": "3f55bbfc-619e-47b2-f183-f0e029b3fc53"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-30 20:31:36--  https://nlp.stanford.edu/software/stanford-tagger-4.2.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://downloads.cs.stanford.edu/nlp/software/stanford-tagger-4.2.0.zip [following]\n",
            "--2022-03-30 20:31:37--  https://downloads.cs.stanford.edu/nlp/software/stanford-tagger-4.2.0.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 78034596 (74M) [application/zip]\n",
            "Saving to: ‘stanford-tagger-4.2.0.zip.3’\n",
            "\n",
            "stanford-tagger-4.2 100%[===================>]  74.42M  4.97MB/s    in 11s     \n",
            "\n",
            "2022-03-30 20:31:48 (6.82 MB/s) - ‘stanford-tagger-4.2.0.zip.3’ saved [78034596/78034596]\n",
            "\n",
            "Archive:  ./stanford-tagger-4.2.0.zip\n",
            "replace stanford-postagger-full-2020-11-17/stanford-postagger-gui.sh? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "CPU times: user 299 ms, sys: 55.9 ms, total: 355 ms\n",
            "Wall time: 36 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up and using the tagger with NLTK"
      ],
      "metadata": {
        "id": "gT_y9OzBbGwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path='./stanford-postagger-full-2020-11-17/models/english-bidirectional-distsim.tagger'\n",
        "jar_tagger_path='./stanford-postagger-full-2020-11-17/stanford-postagger-4.2.0.jar'"
      ],
      "metadata": {
        "id": "xUr6gPwJFKuD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6e8EcS6qqVL5"
      },
      "outputs": [],
      "source": [
        "from nltk.tag.stanford import StanfordPOSTagger # -- deprecated?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kRn3vy0SYlB",
        "outputId": "2a439250-2f6e-42dd-ea8f-88d04211916d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nltk==3.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagger=StanfordPOSTagger(model_path, jar_tagger_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6dDj5bcErgs",
        "outputId": "e6602342-5a3c-4757-f576-553615538169"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNGYvc7GWfrX",
        "outputId": "dee9aff1-60f4-4027-eb33-2813b0f869e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('readme.txt') as f:\n",
        "    text = f.read()\n",
        "    print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPydmPv8Vu9p",
        "outputId": "6633da5d-c7e7-459c-ce5b-106c66bdc1f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He used to read books.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagger.tag(nltk.word_tokenize(\"He used to read books.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovqmsl_yE1ac",
        "outputId": "c1653d13-719b-463d-cc10-322afc1e22d3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('He', 'PRP'),\n",
              " ('used', 'VBD'),\n",
              " ('to', 'TO'),\n",
              " ('read', 'VB'),\n",
              " ('books', 'NNS'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "tagger.tag([st.stem(t) \n",
        "      for t in nltk.word_tokenize(\"He used to read books.\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjcJgsNAFDl6",
        "outputId": "d2c8e826-dec2-43ca-c852-0757894dc847"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('He', 'PRP'),\n",
              " ('use', 'VBP'),\n",
              " ('to', 'TO'),\n",
              " ('read', 'VB'),\n",
              " ('book', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using averaged_perceptron_tagger in NLTK"
      ],
      "metadata": {
        "id": "eOhBNvOHjbgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oiS8XGnajjP",
        "outputId": "835016e4-54f6-4824-8b22-5d0279f795f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.pos_tag(nltk.word_tokenize(\"He used to read books.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trUEM4Y3jj1t",
        "outputId": "bc1c3a82-58ae-44dc-c870-1d9133a5ab16"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('He', 'PRP'),\n",
              " ('used', 'VBD'),\n",
              " ('to', 'TO'),\n",
              " ('read', 'VB'),\n",
              " ('books', 'NNS'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Syntactic Parsing"
      ],
      "metadata": {
        "id": "BVvUf_bfjv7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://nlp.stanford.edu/software/stanford-corenlp-latest.zip'\n",
        "!unzip 'stanford-corenlp-latest.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-dAKHb7QIpI",
        "outputId": "cae9a426-462e-4894-858d-f85a1399e588"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-30 20:32:19--  https://nlp.stanford.edu/software/stanford-corenlp-latest.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-latest.zip [following]\n",
            "--2022-03-30 20:32:19--  https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-latest.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 505207915 (482M) [application/zip]\n",
            "Saving to: ‘stanford-corenlp-latest.zip.1’\n",
            "\n",
            "stanford-corenlp-la 100%[===================>] 481.80M  4.92MB/s    in 94s     \n",
            "\n",
            "2022-03-30 20:33:54 (5.12 MB/s) - ‘stanford-corenlp-latest.zip.1’ saved [505207915/505207915]\n",
            "\n",
            "Archive:  stanford-corenlp-latest.zip\n",
            "replace stanford-corenlp-4.4.0/jaxb-api-2.4.0-b180830.0359-sources.jar? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanfordcorenlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw_7gV3pHJpQ",
        "outputId": "9fae700a-c60c-4a2c-a4e6-66f3367fd658"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stanfordcorenlp in /usr/local/lib/python3.7/dist-packages (3.9.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanfordcorenlp) (2.23.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from stanfordcorenlp) (5.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordcorenlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordcorenlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordcorenlp) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordcorenlp) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stanfordcorenlp\n",
        "sc = stanfordcorenlp.StanfordCoreNLP('/content/stanford-corenlp-4.4.0')"
      ],
      "metadata": {
        "id": "BVPPE8TePAxK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependency parsing"
      ],
      "metadata": {
        "id": "njw19ohd-RLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"He used to read books.\"\n",
        "dependencies = sc.dependency_parse(text)\n",
        "dependencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CAbPIuRQ2Hy",
        "outputId": "ee3ea03b-0ab1-4a34-b181-2e3e0fe49cb4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ROOT', 0, 2),\n",
              " ('nsubj', 2, 1),\n",
              " ('mark', 4, 3),\n",
              " ('xcomp', 2, 4),\n",
              " ('obj', 4, 5),\n",
              " ('punct', 2, 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nltk.word_tokenize(text)\n",
        "for (t, w1, w2) in dependencies:\n",
        "  if w1 < len(tokens) and w2 < len(tokens):\n",
        "    print(\"%s --> %s (%s)\" % (\n",
        "        tokens[w2-1] if w2>0 else \"\", \n",
        "        tokens[w1-1] if w1>0 else \"\",\n",
        "         t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpkrxm6dZCeh",
        "outputId": "3a03b033-0268-4d7b-9c5d-e3d8de5c5a6b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "used -->  (ROOT)\n",
            "He --> used (nsubj)\n",
            "to --> read (mark)\n",
            "read --> used (xcomp)\n",
            "books --> read (obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descriptions of dependency relations: https://universaldependencies.org/u/dep/\n",
        "\n",
        "Demo: https://nlp.stanford.edu/software/stanford-dependencies.html\n"
      ],
      "metadata": {
        "id": "a5u_0xRdfaP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constituent parsing"
      ],
      "metadata": {
        "id": "vwjQVOKv-NpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parsed = sc.parse(text)\n",
        "print(parsed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwAAqvOFQ8Ff",
        "outputId": "7f1d8aed-c9a5-4974-9a4c-ea443bc74fa3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(ROOT\n",
            "  (S\n",
            "    (NP (PRP He))\n",
            "    (VP (VBD used)\n",
            "      (S\n",
            "        (VP (TO to)\n",
            "          (VP (VB read)\n",
            "            (NP (NNS books))))))\n",
            "    (. .)))\n"
          ]
        }
      ]
    }
  ]
}